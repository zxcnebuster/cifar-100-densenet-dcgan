# -*- coding: utf-8 -*-
"""ttrq46-classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sBz9w_hyx37t2JBUnN3oYVi99odtyGGt

**Main imports**
"""

import math
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import matplotlib.pyplot as plt
import os
from IPython import display as disp
from torchvision import transforms

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
#code was built in reference with https://github.com/QingbeiGuo/SG-CNN/tree/master/Classification/DenseNet201/ImageNet/G/models/densenet
# and
# Huang, G. et al. (2018) ‘Densely Connected Convolutional Networks’. arXiv. Available at: http://arxiv.org/abs/1608.06993

# macos code
# import torch
if torch.backends.mps.is_available():
    device = torch.device("mps")
    x = torch.ones(1, device=device)
    print (x)
else:
    print ("MPS device not found.")

"""**Import dataset**"""

# helper function to make getting another batch of data easier
def cycle(iterable):
    while True:
        for x in iterable:
            yield x

class_names = ['apple','aquarium_fish','baby','bear','beaver','bed','bee','beetle','bicycle','bottle','bowl','boy','bridge','bus','butterfly','camel','can','castle','caterpillar','cattle','chair','chimpanzee','clock','cloud','cockroach','couch','crab','crocodile','cup','dinosaur','dolphin','elephant','flatfish','forest','fox','girl','hamster','house','kangaroo','computer_keyboard','lamp','lawn_mower','leopard','lion','lizard','lobster','man','maple_tree','motorcycle','mountain','mouse','mushroom','oak_tree','orange','orchid','otter','palm_tree','pear','pickup_truck','pine_tree','plain','plate','poppy','porcupine','possum','rabbit','raccoon','ray','road','rocket','rose','sea','seal','shark','shrew','skunk','skyscraper','snail','snake','spider','squirrel','streetcar','sunflower','sweet_pepper','table','tank','telephone','television','tiger','tractor','train','trout','tulip','turtle','wardrobe','whale','willow_tree','wolf','woman','worm',]

# transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((32, 32)),
#                         transforms.RandomHorizontalFlip(), transforms.Normalize(mean=[0.5071, 0.4866, 0.4409], std=[0.2664, 0.2555, 0.2751])])

stats = ((0.5071, 0.4866, 0.4409),(0.2664, 0.2555, 0.2751))
train_transform = transforms.Compose([
    transforms.RandomCrop(32,padding=4,padding_mode="reflect"),
    transforms.RandomHorizontalFlip(),
    torchvision.transforms.AugMix(severity=3, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True),
    transforms.ToTensor(),
    transforms.Normalize(*stats)
])

test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(*stats)
])

train_loader = torch.utils.data.DataLoader(
    torchvision.datasets.CIFAR100('data', train=True, download=True, transform=train_transform),
    batch_size=512, shuffle=True, drop_last=True)

# mean = torch.zeros(3)
# std = torch.zeros(3)

# for images, _ in train_loader:
#     for i in range(3):
#         mean[i] += images[:,i,:,:].mean()
#         std[i] += images[:,i,:,:].std()

# mean /= len(train_loader)
# std /= len(train_loader)
# print(mean)
# print(std)
# tensor([0.5071, 0.4866, 0.4409])
# tensor([0.2664, 0.2555, 0.2751])

test_loader = torch.utils.data.DataLoader(
    torchvision.datasets.CIFAR100('data', train=False, download=True, transform=test_transform),
    batch_size=512, shuffle=False, drop_last=True)

train_iterator = iter(cycle(train_loader))
test_iterator = iter(cycle(test_loader))




print(f'> Size of training dataset {len(train_loader.dataset)}')
print(f'> Size of test dataset {len(test_loader.dataset)}')

"""**View some of the test dataset**"""

plt.rcParams['figure.dpi'] = 70
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    img = test_loader.dataset[i][0]
    # reverse normalisation to view images with original colors
    img = img * torch.tensor([0.2664, 0.2555, 0.2751]).view(3, 1, 1) + torch.tensor([0.5071, 0.4866, 0.4409]).view(3, 1, 1)
    img = img.numpy().transpose(1, 2, 0)
    iimg = np.clip(img, 0, 1)
    plt.imshow(img)
    plt.xlabel(class_names[test_loader.dataset[i][1]])
plt.show()

"""##### Helper functions"""

def save_results(params, plot_data, test_acc_arr, model_name):
    params_str = '_'.join([f"{k}{v}" for k, v in params.items()])
    model_dir = f'results/{model_name}_{params_str}'
    os.makedirs(model_dir, exist_ok=True)

    plt.figure()
    plt.plot([x[0] for x in plot_data], [x[1] for x in plot_data], '-', color='tab:grey', label="Train accuracy")
    plt.fill_between([x[0] for x in plot_data], [x[1]-x[2] for x in plot_data], [x[1]+x[2] for x in plot_data], alpha=0.2, color='tab:grey')
    plt.plot([x[0] for x in plot_data], [x[3] for x in plot_data], '-', color='tab:purple', label="Test accuracy")
    plt.fill_between([x[0] for x in plot_data], [x[3]-x[4] for x in plot_data], [x[3]+x[4] for x in plot_data], alpha=0.2, color='tab:purple')
    plt.xlabel('Steps')
    plt.ylabel('Accuracy')
    plt.legend(loc="upper left")
    plot_path = os.path.join(model_dir, 'accuracy_plot.png')
    plt.savefig(plot_path)
    plt.close()

    md_content = f"# Model: {model_name}\n"
    md_content += "## Hyperparameters and Results\n"
    md_content += "| Hyperparameter | Value |\n"
    md_content += "| -------------- | ----- |\n"
    for key, value in params.items():
        md_content += f"| {key} | {value} |\n"
    md_content += f"\n![Accuracy Plot]({plot_path})\n"
    md_content += f"Final Test Accuracy: {np.mean(test_acc_arr):.3f}±{np.std(test_acc_arr):.3f}\n"

    md_path = os.path.join(model_dir, f'{model_name}_report.md')
    with open(md_path, 'w') as f:
        f.write(md_content)

    summary_path = 'results/summary.md'
    if os.path.exists(summary_path):
        with open(summary_path, 'r') as f:
            summary_content = f.readlines()
    else:
        headers = "| Model | " + " | ".join(params.keys()) + " | Test Accuracy |\n"
        separator = "| ---- | " + " | ".join(["----"] * len(params.keys())) + " | ------------- |\n"
        summary_content = [headers, separator]

    summary_line = f"| {model_name} | " + " | ".join([str(params[k]) for k in params.keys()]) + f" | {np.mean(test_acc_arr):.3f}±{np.std(test_acc_arr):.3f} |\n"
    summary_content.append(summary_line)

    header = summary_content[:2]
    data_lines = summary_content[2:]
    data_lines.sort(key=lambda x: float(x.split('|')[-2].split('±')[0]), reverse=True)
    summary_content = header + data_lines

    with open(summary_path, 'w') as f:
        f.writelines(summary_content)

"""**Model**"""

import math
import torch
import torch.nn as nn
from torch.nn import functional as F

class SingleLayer(nn.Module):
    def __init__(self, nChannels, growthRate):
        super(SingleLayer, self).__init__()
        interChannels = 4*growthRate
        self.bn1 = nn.BatchNorm2d(nChannels)
        self.conv1 = nn.Conv2d(nChannels, interChannels, kernel_size=1,
                               bias=False)
        self.bn2 = nn.BatchNorm2d(interChannels)
        self.conv2 = nn.Conv2d(interChannels, growthRate, kernel_size=3,
                               padding=1, bias=False)

    def forward(self, x):
        out = self.conv1(F.relu(self.bn1(x)))
        out = self.conv2(F.relu(self.bn2(out)))
        out = torch.cat((x, out), 1)
        return out

class Transition(nn.Module):
    def __init__(self, nChannels, nOutChannels):
        super(Transition, self).__init__()
        self.bn1 = nn.BatchNorm2d(nChannels)
        self.conv1 = nn.Conv2d(nChannels, nOutChannels, kernel_size=1,
                               bias=False)

    def forward(self, x):
        out = self.conv1(F.relu(self.bn1(x)))
        out = F.avg_pool2d(out, 2)
        return out


class DenseNet(nn.Module):
    def __init__(self, params):
        input_channel = params['input_channel']
        growthRate = params['growthRate']
        depth = params['depth']
        reduction = params['reduction']
        n_classes = params['n_classes']

        super(DenseNet, self).__init__()

        nDenseBlocks = (depth-4) // 3
        nDenseBlocks //= 2

        nChannels = 2*growthRate
        self.conv1 = nn.Conv2d(input_channel, nChannels, kernel_size=3, padding=1,
                               bias=False)
        self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks)
        nChannels += nDenseBlocks*growthRate
        nOutChannels = int(math.floor(nChannels*reduction))
        self.trans1 = Transition(nChannels, nOutChannels)

        nChannels = nOutChannels
        self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks)
        nChannels += nDenseBlocks*growthRate
        nOutChannels = int(math.floor(nChannels*reduction))
        self.trans2 = Transition(nChannels, nOutChannels)

        nChannels = nOutChannels
        self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks)
        nChannels += nDenseBlocks*growthRate
        nOutChannels = int(math.floor(nChannels*reduction))
        self.trans3 = Transition(nChannels, nOutChannels)

        nChannels = nOutChannels
        self.dense4 = self._make_dense(nChannels, growthRate, nDenseBlocks)
        nChannels += nDenseBlocks*growthRate


        self.bn1 = nn.BatchNorm2d(nChannels)
        self.fc = nn.Linear(nChannels, n_classes)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
            elif isinstance(m, nn.Linear):
                m.bias.data.zero_()

    def _make_dense(self, nChannels, growthRate, nDenseBlocks):
        layers = []
        for i in range(int(nDenseBlocks)):
            layers.append(SingleLayer(nChannels, growthRate))
            nChannels += growthRate
        return nn.Sequential(*layers)

    def forward(self, x):
        out = self.conv1(x)
        out = self.trans1(self.dense1(out))
        out = self.trans2(self.dense2(out))
        out = self.trans3(self.dense3(out))
        out = self.dense4(out)
        out = F.relu(self.bn1(out))
        out = torch.squeeze(F.adaptive_avg_pool2d(out, 1))
        out = torch.flatten(out, 1)
        out = self.fc(out)

        return out

# hyperparameters
params = {
    'input_channel': 3,  # number of channels
    'n_classes':  100, # number of classes for CIFAR-100,
    'growthRate': 8,
    'depth':36,
    'reduction':0.58275,
    'model_name': 'DensetNet',
    'lr': 0.0075
}

N = DenseNet(params).to(device)

# print the number of parameters - this should be included in your report
print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')

if len(torch.nn.utils.parameters_to_vector(N.parameters())) > 100000:
    print("> Warning: you have gone over your parameter budget and will have a grade penalty!")


optimiser = torch.optim.Adam(N.parameters(), lr=params['lr'])
plot_data = []
steps = 0

"""**Main training and testing loop**"""

# keep within our optimisation step budget
while (steps < 10000):

    # arrays for metrics
    train_loss_arr = np.zeros(0)
    train_acc_arr = np.zeros(0)
    test_acc_arr = np.zeros(0)

    # iterate through some of the train dateset
    for i in range(1000):
        x,t = next(train_iterator)
        x,t = x.to(device), t.to(device)

        optimiser.zero_grad()
        p = N(x)
        pred = p.argmax(dim=1, keepdim=True)
        loss = torch.nn.functional.cross_entropy(p, t)
        loss.backward()
        optimiser.step()
        steps += 1

        train_loss_arr = np.append(train_loss_arr, loss.cpu().data)
        train_acc_arr = np.append(train_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())

    # iterate over the entire test dataset
    for x,t in test_loader:
        x,t = x.to(device), t.to(device)
        p = N(x)
        loss = torch.nn.functional.cross_entropy(p, t)
        pred = p.argmax(dim=1, keepdim=True)
        test_acc_arr = np.append(test_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())

    # print loss and accuracy
    print('steps: {:.2f}, train loss: {:.3f}, train acc: {:.3f}±{:.3f}, test acc: {:.3f}±{:.3f}'.format(
        steps, train_loss_arr.mean(),train_acc_arr.mean(),train_acc_arr.std(),test_acc_arr.mean(),test_acc_arr.std()))

    # plot accuracy graph
    plot_data.append([steps, np.array(train_acc_arr).mean(), np.array(train_acc_arr).std(), np.array(test_acc_arr).mean(), np.array(test_acc_arr).std()])
    reward_list = []
    plt.plot([x[0] for x in plot_data], [x[1] for x in plot_data], '-', color='tab:grey', label="Train accuracy")
    plt.fill_between([x[0] for x in plot_data], [x[1]-x[2] for x in plot_data], [x[1]+x[2] for x in plot_data], alpha=0.2, color='tab:grey')
    plt.plot([x[0] for x in plot_data], [x[3] for x in plot_data], '-', color='tab:purple', label="Test accuracy")
    plt.fill_between([x[0] for x in plot_data], [x[3]-x[4] for x in plot_data], [x[3]+x[4] for x in plot_data], alpha=0.2, color='tab:purple')
    plt.xlabel('Steps')
    plt.ylabel('Accuracy')
    plt.legend(loc="upper left")
    plt.show()
    disp.clear_output(wait=True)

save_results(params, plot_data, test_acc_arr, params['model_name'])

torch.save(N.state_dict(), 'classificator_state_dict.pth')
torch.save(N, 'classificator_entire_model.pth')

def plot_image(i, predictions_array, true_label, img):
    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    norm_mean = np.array([0.5071, 0.4866, 0.4409])
    norm_std = np.array([0.2664, 0.2555, 0.2751])

    img = img * norm_std.reshape(3, 1, 1) + norm_mean.reshape(3, 1, 1)
    img = img.transpose(1, 2, 0)
    img = np.clip(img, 0, 1)  # Ensure the image values are valid
    # iimg = np.clip(img, 0, 1)
    plt.imshow(img)

    predicted_label = np.argmax(predictions_array)
    color = '#335599' if predicted_label == true_label else '#ee4433'

    plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                  100*np.max(predictions_array),
                                  class_names[true_label]),
                                  color=color)

def plot_value_array(i, predictions_array, true_label):
    predictions_array, true_label = predictions_array[i], true_label[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    thisplot = plt.bar(range(100), predictions_array, color="#777777")
    plt.ylim([0, 1])
    predicted_label = np.argmax(predictions_array)

    thisplot[predicted_label].set_color('#ee4433')
    thisplot[true_label].set_color('#335599')

test_images, test_labels = next(test_iterator)
test_images, test_labels = test_images.to(device), test_labels.to(device)
test_preds = torch.softmax(N(test_images), dim=1).data.cpu().numpy()
num_rows = 8
num_cols = 4
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
    plt.subplot(num_rows, 2*num_cols, 2*i+1)
    plot_image(i, test_preds, test_labels.cpu().numpy(), test_images.cpu().numpy()) # Used .numpy() here
    plt.subplot(num_rows, 2*num_cols, 2*i+2)
    plot_value_array(i, test_preds, test_labels.cpu().numpy())

