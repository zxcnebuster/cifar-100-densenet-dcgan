# -*- coding: utf-8 -*-
"""dcgan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_aFntQKo71U6SHQW99mYAdP5RemG-Pmv
"""

import math
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import matplotlib.pyplot as plt
from IPython import display as disp
from torchvision.utils import make_grid

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

# helper function to make getting another batch of data easier
def cycle(iterable):
    while True:
        for x in iterable:
            yield x

class_names = ['apple','aquarium_fish','baby','bear','beaver','bed','bee','beetle','bicycle','bottle','bowl','boy','bridge','bus','butterfly','camel','can','castle','caterpillar','cattle','chair','chimpanzee','clock','cloud','cockroach','couch','crab','crocodile','cup','dinosaur','dolphin','elephant','flatfish','forest','fox','girl','hamster','house','kangaroo','computer_keyboard','lamp','lawn_mower','leopard','lion','lizard','lobster','man','maple_tree','motorcycle','mountain','mouse','mushroom','oak_tree','orange','orchid','otter','palm_tree','pear','pickup_truck','pine_tree','plain','plate','poppy','porcupine','possum','rabbit','raccoon','ray','road','rocket','rose','sea','seal','shark','shrew','skunk','skyscraper','snail','snake','spider','squirrel','streetcar','sunflower','sweet_pepper','table','tank','telephone','television','tiger','tractor','train','trout','tulip','turtle','wardrobe','whale','willow_tree','wolf','woman','worm',]

stats = ((0.5071, 0.4866, 0.4409),(0.2664, 0.2555, 0.2751))
train_loader = torch.utils.data.DataLoader(
    torchvision.datasets.CIFAR100('data', train=True, download=True, transform=torchvision.transforms.Compose([
        torchvision.transforms.RandomHorizontalFlip(),
        torchvision.transforms.AugMix(severity=3, mixture_width=3, chain_depth=-1, alpha=1.0, all_ops=True),
        torchvision.transforms.ToTensor(),
        torchvision.transforms.Normalize(*stats)
    ])),
    batch_size=64, drop_last=True)

test_loader = torch.utils.data.DataLoader(
    torchvision.datasets.CIFAR100('data', train=False, download=True, transform=torchvision.transforms.Compose([
        torchvision.transforms.ToTensor(),
        torchvision.transforms.Normalize(*stats)
    ])),
    batch_size=64, drop_last=True)

train_iterator = iter(cycle(train_loader))
test_iterator = iter(cycle(test_loader))

print(f'> Size of training dataset {len(train_loader.dataset)}')
print(f'> Size of test dataset {len(test_loader.dataset)}')

# let's view some of the training data
plt.rcParams['figure.dpi'] = 100
x,t = next(train_iterator)
x,t = x.to(device), t.to(device)
plt.imshow(torchvision.utils.make_grid(x).cpu().numpy().transpose(1, 2, 0), cmap=plt.cm.binary)
plt.show()

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        output_size = 32
        self.discr = nn.Sequential(
            nn.Conv2d(3, output_size, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(output_size),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(output_size, output_size * 2, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(output_size * 2),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(output_size * 2, output_size * 4, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(output_size * 4),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(output_size * 4, 1, kernel_size=4, stride=2, padding=1, bias=False),
            nn.Flatten(),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.discr(x)
        return x

latent_size = 128

class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        output_size = 32
        self.gen = nn.Sequential(
            nn.ConvTranspose2d(latent_size, output_size * 4, kernel_size=4, stride=1, padding=0, bias=False),  # Reduced initial layer size
            nn.BatchNorm2d(output_size * 4),
            nn.LeakyReLU(0.2, inplace=True),

            nn.ConvTranspose2d(output_size * 4, output_size * 2, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(output_size * 2),
            nn.LeakyReLU(0.2, inplace=True),

            nn.ConvTranspose2d(output_size * 2, output_size, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(output_size),
            nn.LeakyReLU(0.2, inplace=True),

            nn.ConvTranspose2d(output_size, 3, kernel_size=4, stride=2, padding=1, bias=False),
            nn.Tanh()
        )

    def forward(self, x):
        x = self.gen(x)
        return x

generator = Generator().to(device)
# generator.load_state_dict(torch.load('generator_state_dict.pth'))
# generator.eval()
discriminator = Discriminator().to(device)

noise = torch.randn(64, latent_size, 1, 1, device = device)
fake_images = generator(noise)

import torch.nn.functional as F

batch_size = 128

def train_discriminator(real_images, opt_d):
    opt_d.zero_grad()

    real_preds = discriminator(real_images)
    real_targets = (torch.ones(real_images.size(0), 1) - torch.FloatTensor(real_images.size(0), 1).uniform_(0.0, 0.05)).to(device)
    real_loss = criterion["discriminator"](real_preds, real_targets)
    real_score = torch.mean(real_preds).item()

    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)
    fake_images = generator(latent)

    fake_targets = torch.zeros(fake_images.size(0), 1, device=device) + torch.rand(fake_images.size(0), 1, device=device) * 0.05
    fake_preds = discriminator(fake_images)
    fake_loss = criterion["discriminator"](fake_preds, fake_targets)
    fake_score = torch.mean(fake_preds).item()

    loss = real_loss + fake_loss
    loss.backward()
    opt_d.step()
    return loss.item(), real_score, fake_score

def train_generator(opt_g):
    opt_g.zero_grad()

    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)
    fake_images = generator(latent)

    preds = discriminator(fake_images)
    targets = torch.ones(batch_size, 1, device=device)
    loss = criterion["discriminator"](preds, targets)

    loss.backward()
    opt_g.step()

    return loss.item()

lr = 0.0008

model = {
    "discriminator": discriminator,
    "generator": generator
}

criterion = {
    "discriminator": nn.BCELoss(),
    "generator": nn.BCELoss()
}

print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(generator.parameters()))}')
print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(discriminator.parameters()))}')

def denorm(img_tensors):
    stats = (0.5071, 0.4866, 0.4409),(0.2664, 0.2555, 0.2751)
    return img_tensors * stats[1][0] + stats[0][0]

def show_images(images, nmax=64):
    fig, ax = plt.subplots(figsize=(8, 8))
    ax.set_xticks([]); ax.set_yticks([])
    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))
    plt.show()

epochs = 50
steps = 0

torch.cuda.empty_cache()
generator.train()
discriminator.train()
losses_g = []
losses_d = []
real_scores = []
fake_scores = []

lowest_loss_g = np.inf


opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))
opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))

while (steps < 50000):

    for i in range(1000):
        real_images,t = next(train_iterator)
        real_images,t = real_images.to(device), t.to(device)


        loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)

        loss_g = train_generator(opt_g)

        steps += 1

    losses_g.append(loss_g)
    losses_d.append(loss_d)
    real_scores.append(real_score)
    fake_scores.append(fake_score)

    if losses_g[-1] < lowest_loss_g:
        print(f'Generator score increase from {lowest_loss_g} to {losses_g[-1]}. Saving weights')
        lowest_loss_g = losses_g[-1]
        torch.save(generator.state_dict(), 'gen_best_weights.pth')


    print("Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}".format(
        steps//1000, epochs, loss_g, loss_d, real_score, fake_score))

    n_images = 4
    fixed_latent = torch.randn(n_images, latent_size, 1, 1, device=device)
    fake_images = model["generator"](fixed_latent)
    show_images(fake_images.cpu())

torch.save(generator.state_dict(), 'gen_state_dict.pth')
torch.save(generator, 'gen_entire_model.pth')
torch.save(discriminator.state_dict(), 'dis_state_dict.pth')
torch.save(discriminator, 'dis_entire_model.pth')

common_latent_set = torch.empty(0, latent_size, 1, 1, device = device)

for j in range(8):
  alpha = np.linspace(0, 1, 8)
  latent_1 = torch.randn(1, latent_size, 1, 1, device=device)
  latent_2 = torch.randn(1, latent_size, 1, 1, device=device)
  common_latent_set = torch.cat((common_latent_set, latent_1), 0)

  for i in range(6):
    common_latent_set = torch.cat((common_latent_set, alpha[i + 1] * latent_2 + (1 - alpha[i + 1]) * latent_1), 0)

  common_latent_set = torch.cat((common_latent_set, latent_2), 0)

cur_latent_fake_images = model["generator"](common_latent_set)

fig, ax = plt.subplots(figsize=(8, 8))
ax.set_xticks([]); ax.set_yticks([])

ax.imshow(make_grid(denorm(cur_latent_fake_images.detach()[:64]), nrow=8).cpu().permute(1, 2, 0).numpy())
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install clean-fid
# import os
# from cleanfid import fid
# from torchvision.utils import save_image

import os

real_images_dir = 'real_images'
generated_images_dir = 'generated_images'
num_samples = 10000 # do not change


def setup_directory(directory):
    if os.path.exists(directory):
        !rm -r {directory}
    os.makedirs(directory)

setup_directory(real_images_dir)
setup_directory(generated_images_dir)


num_generated = 0
while num_generated < num_samples:


    z = torch.randn(batch_size, latent_size, 1, 1, device = device)
    samples_batch = model["generator"](z).cpu().detach()

    for image in samples_batch:
        if num_generated >= num_samples:
            break
        save_image(image, os.path.join(generated_images_dir, f"gen_img_{num_generated}.png"))
        num_generated += 1


num_saved_real = 0
while num_saved_real < num_samples:
    real_samples_batch, _ = next(test_iterator)
    for image in real_samples_batch:
        if num_saved_real >= num_samples:
            break
        save_image(image, os.path.join(real_images_dir, f"real_img_{num_saved_real}.png"))
        num_saved_real += 1

score = fid.compute_fid(real_images_dir, generated_images_dir, mode="clean")
print(f"FID score: {score}")

def count_items_in_folder(folder_path):
    items = os.listdir(folder_path)
    num_items = len(items)
    return num_items


folder_path = real_images_dir
num_items = count_items_in_folder(folder_path)
print("Number of items in the folder:", num_items)
folder_path = generated_images_dir
num_items = count_items_in_folder(folder_path)
print("Number of items in the folder:", num_items)

def zip_directory(folder_path, output_path):
    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        folder_path = os.path.normpath(folder_path)
        for root, dirs, files in os.walk(folder_path):
            for file in files:
                file_path = os.path.join(root, file)
                in_zip_path = os.path.relpath(file_path, folder_path)
                zipf.write(file_path, in_zip_path)

zip_directory('generated_images', 'generated_images.zip')

from google.colab import files
files.download("/generated_images.zip")

zip_directory('/real_images', '/real_images.zip')

files.download("/real_images.zip")

